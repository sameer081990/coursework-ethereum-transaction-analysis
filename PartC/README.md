# Part C
## Requirement
The requirement of this part was find out the most active miners by the size of blocks mined. It was implemneted in both MapReduce and Spark.

## Deliverables
The MapReduce programmes produced were:
* [PartC_hadoop.py](./PartC_hadoop.py) - Finding out the most popular smart contracts using MapReduce.
* [PartC_spark.py](./PartC_spark.py) - Finding out the most popular smart contracts using Spark.

## Results
Both programme had produced the same results:
|Miner address|Total mined size|
| ------------ | ------------ |
|0xea674fdde714fd979de3edf0f56aa9716b898ec8|10074354653655|
|0x829bd824b016326a401d083b33d092293333a830|5367550371603|
|0x52bc44d5378309ee2abf1539bf71de1b7d7be3b5|5229980806097|
|0x5a0b54d5dc17e0aadc383d2db43b0a0d3e029c4c|5130173783912|
|0x2a65aca4d5fc5b5c859090a6c34d164135398226|4003112390492|
|0xb2930b35844a230f00e51431acae96fe543a0347|2934253552655|
|0x61c808d82a3ac53231750dadc13c777b59310bd9|1903638005559|
|0x4bb96091ee9d802ed039c4d1a5f6216f90f81b01|1234425348141|
|0x1e9939daaad6924ad004c2560e90804164900341|790079447850|
|0xf3b9d2c81f2b24b0fa0acaaa865b7d9ced5fc2fb|641031052841|
